#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ›¿æ¢ HTML æ–‡ä»¶ä¸­çš„å›¾ç‰‡é“¾æ¥ä¸º R2 URLï¼ˆæ”¯æŒ URL ç¼–ç è·¯å¾„ï¼‰
"""
import os
import sys
import urllib.parse
from pathlib import Path
from bs4 import BeautifulSoup

# æ”¯æŒçš„å›¾ç‰‡æ‰©å±•å
IMAGE_EXTS = {'.jpg', '.jpeg', '.png', '.gif', '.webp', '.svg', '.bmp', '.ico'}

def is_image_file(path):
    """åˆ¤æ–­æ˜¯å¦ä¸ºå›¾ç‰‡æ–‡ä»¶"""
    return path.suffix.lower() in IMAGE_EXTS

def get_all_html_files(directory):
    """è·å–ç›®å½•ä¸‹æ‰€æœ‰ HTML æ–‡ä»¶"""
    html_files = []
    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith('.html'):
                html_files.append(Path(root) / file)
    return html_files

def replace_image_links(html_file, public_dir, base_url):
    """æ›¿æ¢ HTML æ–‡ä»¶ä¸­çš„å›¾ç‰‡é“¾æ¥"""
    try:
        with open(html_file, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        soup = BeautifulSoup(html_content, 'html.parser')
        changed = False
        
        for img in soup.find_all('img'):
            src = img.get('src', '').strip()
            
            # è·³è¿‡ç©ºé“¾æ¥å’Œå¤–éƒ¨é“¾æ¥
            if not src or src.startswith(('http://', 'https://', '//', 'data:')):
                continue
            
            # å¤„ç†ç›¸å¯¹è·¯å¾„ï¼ˆ./ æˆ– ../ï¼‰
            if src.startswith(('./', '../')):
                # è½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼ˆåŸºäº HTML æ–‡ä»¶ä½ç½®ï¼‰
                html_rel_path = html_file.relative_to(public_dir)
                abs_path = (Path(public_dir) / html_rel_path.parent / src).resolve()
                rel_to_public = abs_path.relative_to(Path(public_dir).resolve())
                normalized_src = '/' + rel_to_public.as_posix()
            else:
                # å¤„ç†ç»å¯¹è·¯å¾„ï¼ˆ/ å¼€å¤´ï¼‰
                normalized_src = src if src.startswith('/') else '/' + src
            
            # å°è¯•ä¸¤ç§è·¯å¾„ï¼šåŸå§‹ç¼–ç è·¯å¾„ + è§£ç åè·¯å¾„
            candidates = [
                Path(public_dir) / normalized_src.lstrip('/'),
                Path(public_dir) / urllib.parse.unquote(normalized_src.lstrip('/'))
            ]
            
            for local_path in candidates:
                if local_path.exists() and is_image_file(local_path):
                    new_src = base_url.rstrip('/') + normalized_src
                    img['src'] = new_src
                    changed = True
                    print(f"âœ… {html_file.relative_to(Path.cwd())}: {normalized_src} â†’ {new_src}")
                    break
            else:
                # è°ƒè¯•ï¼šæ‰“å°æœªåŒ¹é…çš„å›¾ç‰‡
                print(f"âš ï¸  æœªæ‰¾åˆ°æœ¬åœ°æ–‡ä»¶: {normalized_src} (å°è¯•è·¯å¾„: {candidates[0]}, {candidates[1]})")
        
        if changed:
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(str(soup))
        
        return changed
    
    except Exception as e:
        print(f"âŒ å¤„ç†æ–‡ä»¶ {html_file} æ—¶å‡ºé”™: {e}")
        return False

def main():
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python replace-img-links.py <public_dir> <r2_base_url>")
        print("ç¤ºä¾‹: python replace-img-links.py public https://yuzexiaoyu.8af8989ece65309e48121cc872681506.r2.cloudflarestorage.com")
        sys.exit(1)
    
    public_dir = sys.argv[1]
    r2_base_url = sys.argv[2].rstrip('/')
    
    if not Path(public_dir).exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {public_dir}")
        sys.exit(1)
    
    print(f"ğŸ” æ‰«æç›®å½•: {public_dir}")
    
    html_files = get_all_html_files(public_dir)
    print(f"ğŸ“„ æ‰¾åˆ° {len(html_files)} ä¸ª HTML æ–‡ä»¶")
    
    changed_count = 0
    for html_file in html_files:
        if replace_image_links(html_file, public_dir, r2_base_url):
            changed_count += 1
    
    print(f"\nâœ¨ å®Œæˆï¼å…±ä¿®æ”¹ {changed_count} ä¸ªæ–‡ä»¶")
    print(f"ğŸ”— R2 åŸºç¡€ URL: {r2_base_url}")

if __name__ == '__main__':
    main()